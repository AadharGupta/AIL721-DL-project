# -*- coding: utf-8 -*-
"""transf-learn-using-utk-code - PART 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tNpfT6D9zn9HHyt4vzASC6C4xfKhfKYX
"""

import mne

raw = mne.io.read_raw_eeglab("/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Right_10trials.set", preload=False)
print("EEG Channels in this file:")
print(raw.ch_names)


bci42a_channels = [
    'Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4',
    'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',
    'CP3', 'CP1', 'CPz', 'CP2', 'CP4',
    'P1', 'Pz', 'P2', 'POz'
]

aad_custom_ch= ['C3', 'C4', 'Cz']

"""EEG Channels in this file:
['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T7', 'T8', 'P7', 'P8', 'Fz', 'Cz', 'Pz', 'IO', 'FC1', 'FC2', 'CP1', 'CP2', 'FC5', 'FC6', 'CP5', 'CP6', 'FT9', 'FT10', 'TP9', 'TP10']

## step 0 ) functions
"""

import os
import numpy as np
import tensorflow as tf
import mne # For loading GDF and processing
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import itertools
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (Input, Conv2D, DepthwiseConv2D, SeparableConv2D,
                                     BatchNormalization, Activation, AveragePooling2D,
                                     Dropout, Flatten, Dense, Concatenate)
from tensorflow.keras.constraints import max_norm # Re-added for EEGNet_MSD
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
from tensorflow.keras.optimizers.schedules import LearningRateSchedule
from tensorflow.keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, EarlyStopping # Added EarlyStopping
import time
import logging
import math
import traceback

import numpy as np
import pandas as pd
import mne
def extract_epochs_from_set_and_csv(set_file, csv_file, label, bandpass=(5., 35.)):

#def extract_epochs_from_set_and_csv(set_file, csv_file, ch_name_list, label, bandpass=(5., 35.)):
    """
    Extracts EEG segments from a .set file based on start-stop times in a CSV file.

    Args:
        set_file (str): Path to the .set EEG file.
        csv_file (str): CSV file with 'start' and 'stop' columns (in seconds).
        label (int): Integer label to assign to this class (e.g., 0 for left, 1 for right).
        bandpass (tuple): (low_freq, high_freq) bandpass filter in Hz.

    Returns:
        X (np.ndarray): EEG segments of shape (n_trials, channels, samples, 1)
        y (np.ndarray): Labels of shape (n_trials,)
        sfreq (float): Sampling frequency
    """
    segment_duration= 3.0 #--- 3 sec fixed duration otherwise error that alll train samples of varying len
    raw = mne.io.read_raw_eeglab(set_file, preload=True)

    #----------> choose channnels
    #raw.pick_channels(ch_name_list)  # or use the full BCI channel list

    raw.filter(bandpass[0], bandpass[1], fir_design='firwin')
    sfreq = raw.info['sfreq']
    data = raw.get_data()  # shape: (channels, samples)

    df = pd.read_csv(csv_file)
    X_list = []
    for _, row in df.iterrows():
        start_sec = float(row['start'])
        stop_sec = float(row['stop'])
        start_sample = int(start_sec * sfreq)
        #stop_sample = int(stop_sec * sfreq)
        stop_sample = start_sample + int(segment_duration * sfreq)


        if stop_sample > data.shape[1]:
            print(f"Warning: stop sample {stop_sample} exceeds EEG length. Skipping this segment.")
            continue

        segment = data[:, start_sample:stop_sample]  # shape: (channels, samples_in_segment)

        # Skip very short segments
        if segment.shape[1] < int(0.5 * sfreq):  # Less than 0.5 sec
            print(f"Warning: segment too short ({segment.shape[1]} samples). Skipping.")
            continue

        segment = segment[..., np.newaxis]  # Add channel dimension → (channels, samples, 1)
        X_list.append(segment)

    X = np.array(X_list)
    y = np.full((len(X_list),), label)
    return X, y, sfreq



def combine_and_shuffle_epochs (X_list, y_list, seed=42):  #(X1, y1, X2, y2, seed=42):
    """
    Combines and shuffles two sets of EEG epochs with their labels.

    Args:
        X1, y1: Data and labels from class 1
        X2, y2: Data and labels from class 2

    Returns:
        X_combined: Shuffled EEG data
        y_combined: Corresponding shuffled labels
    """
    X = np.concatenate( X_list, axis=0)       #[X1, X2], axis=0)
    y = np.concatenate( y_list, axis=0)                  #[y1, y2], axis=0)

    # Shuffle
    idx = np.random.RandomState(seed=seed).permutation(len(y))
    X_shuffled = X[idx]
    y_shuffled = y[idx]

    return X_shuffled, y_shuffled

def preprocess_epochs(X, sfreq, reject_thresh_uv=150, downsample_to=None, selected_channels=None):
    """
    Apply post-loading preprocessing to EEG data:
    - Artifact rejection (based on peak-to-peak threshold)
    - Optional downsampling
    - Optional channel selection

    Args:
        X (np.ndarray): Shape (n_trials, channels, samples, 1)
        sfreq (float): Original sampling rate
        reject_thresh_uv (float): Threshold in microvolts for rejection (default 150 uV)
        downsample_to (float): Target sampling frequency (Hz); if None, keep original
        selected_channels (list): Indices of channels to keep; if None, keep all

    Returns:
        X_clean (np.ndarray): Cleaned EEG data
        kept_idx (list): Indices of retained trials
        new_sfreq (float): Effective sampling rate after downsampling
    """
    assert X.ndim == 4, "X should be shape (trials, channels, samples, 1)"
    reject_thresh = reject_thresh_uv * 1e-6  # Convert to volts

    X = X.squeeze(-1)  # Remove channel dim for now → (trials, ch, time)

    # Step 1: Select specific channels
    if selected_channels is not None:
        X = X[:, selected_channels, :]
        print(f" Selected {len(selected_channels)} channels.")

    # Step 2: Artifact rejection based on peak-to-peak
    keep_trials = []
    for i, trial in enumerate(X):
        ptp = np.ptp(trial, axis=1)  # Peak-to-peak per channel
        if np.any(ptp > reject_thresh):
            continue  # Reject this trial
        keep_trials.append(i)

    X_clean = X[keep_trials]
    print(f" Retained {len(keep_trials)} out of {X.shape[0]} trials after artifact rejection.")

    # Step 3: Downsampling
    new_sfreq = sfreq
    if downsample_to is not None and downsample_to < sfreq:
        ratio = int(sfreq / downsample_to)
        X_clean = X_clean[:, :, ::ratio]
        new_sfreq = sfreq / ratio
        print(f" Downsampled from {sfreq} Hz to {new_sfreq} Hz (factor={ratio}).")

    # Add back channel dim for CNN
    X_clean = X_clean[..., np.newaxis]
    return X_clean, keep_trials, new_sfreq

'''#----------------- LEFT ------------------
label_L = 1
csv_f= "/kaggle/input/timestamps/label and timestamps csv/aadhar_bicepcurl_Left_10trials.csv"
set_f= "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Left_10trials.set"
freq_band_filt = (8., 30.)
X_L, y_L, sfreq_L = extract_epochs_from_set_and_csv(set_f, csv_f, label_L, bandpass=freq_band_filt)

#----------------- RIGHT ------------------
label_r = 2
csv_f= "/kaggle/input/timestamps/label and timestamps csv//kaggle/input/timestamps/label and timestamps csv/aadhar_bicepcurl_Right_10trials.csv"
set_f= "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files//kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Right_10trials.set"
X_r, y_r, sfreq_R = extract_epochs_from_set_and_csv(set_f, csv_f, label_L, bandpass=freq_band_filt)'''

print(X_L.shape)
y_L.shape

"""## data prep"""

import os, time, numpy as np, tensorflow as tf
from sklearn.model_selection import train_test_split


# --- Config ---
set_l_1 = "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Left_10trials.set"
set_r_1= "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Right_10trials.set"
csv_left_1 = "/kaggle/input/timestamps/label and timestamps csv/aadhar_bicepcurl_Left_10trials.csv"
csv_right_1 = "//kaggle/input/timestamps/label and timestamps csv/aadhar_bicepcurl_Right_10trials.csv"

set_l_2 = "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_LeftRRight_15trials.set"
set_r_2 = set_l_2
csv_left_2 = "/kaggle/input/timestamps/label and timestamps csv/aadhar_bicepcurl_LeftRRight_15trials____LEFT_ONLY___.csv"
csv_right_2 = "/kaggle/input/timestamps/label and timestamps csv/aadhar_bicepcurl_LeftRRight_15trials____RIGHT_ONLY___.csv"


label_left = 0
label_right = 1
NUM_CLASSES = 2
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

# --- Prepare Data ---

#Left
X_left_1, y_left_1, sfreq = extract_epochs_from_set_and_csv(set_l_1, csv_left_1, label=label_left)
X_left_2, y_left_2, _ = extract_epochs_from_set_and_csv(set_l_2, csv_left_2, label=label_left)

X_right_1, y_right_1, _ = extract_epochs_from_set_and_csv(set_r_1, csv_right_1, label=label_right)
X_right_2, y_right_2, _ = extract_epochs_from_set_and_csv(set_r_2, csv_right_2, label=label_right)


#X_all, y_all = combine_and_shuffle_epochs(X_left, y_left, X_right, y_right)
X_all, y_all = combine_and_shuffle_epochs ([X_left_1,X_right_1,X_left_2,X_right_2], [y_left_1,y_right_1,y_left_2,y_right_2])


y_cat = to_categorical(y_all, num_classes=NUM_CLASSES)
X_train, X_val, y_train, y_val = train_test_split(X_all, y_cat, test_size=0.3, stratify=y_all, random_state=42)

y_val

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, Conv2D, DepthwiseConv2D, SeparableConv2D,
    BatchNormalization, Activation, AveragePooling2D,
    Dropout, Flatten, Dense
)
from tensorflow.keras.regularizers import l2

# --- Model ---

def build_q_eegnet(input_shape, num_classes=2, dropout_rate=0.5, l2_rate=1e-4, **kwargs):
    """Placeholder 'Quantized-like' EEGNet (Lighter variant for demonstration)."""
    n_channels, n_times, _ = input_shape
    inputs = Input(shape=input_shape, name='Input')
    # Block 1 - Reduced Filters/Depth Multiplier
    F1 = 8 # Reduced from 16 in build_eegnet
    D = 1 # Reduced from 2
    kernLength = 51 # Keep same as build_eegnet
    x = Conv2D(F1, (1, kernLength), padding='same', use_bias=False, kernel_regularizer=l2(l2_rate))(inputs)
    x = BatchNormalization()(x)
    x = DepthwiseConv2D((n_channels, 1), depth_multiplier=D, use_bias=False, depthwise_regularizer=l2(l2_rate))(x)
    x = BatchNormalization()(x)
    x = Activation('elu')(x)
    x = AveragePooling2D((1, 4))(x)
    x = Dropout(dropout_rate)(x)
    # Block 2 - Reduced Filters
    F2 = 16 # Reduced from 32
    kernLength2 = 15 # Keep same as build_eegnet
    x = SeparableConv2D(F2, (1, kernLength2), padding='same', use_bias=False, depthwise_regularizer=l2(l2_rate), pointwise_regularizer=l2(l2_rate))(x)
    x = BatchNormalization()(x)
    x = Activation('elu')(x)
    x = AveragePooling2D((1, 8))(x)
    x = Dropout(dropout_rate)(x)
    # Classification Head - Reduced Dense Layer
    x = Flatten()(x)
    x = Dense(32, activation='elu', kernel_regularizer=l2(l2_rate))(x) # Reduced from 64
    x = Dropout(dropout_rate)(x)
    outputs = Dense(num_classes, activation='softmax')(x)
    return Model(inputs, outputs, name='build_q_eegnet')


input_shape = X_train.shape[1:]
model = build_q_eegnet(input_shape=input_shape, num_classes=NUM_CLASSES, dropout_rate=0.25, l2_rate=0.0001)
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# --- Logging Callback ---
class EpochLogger(Callback):
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        print(f"Epoch {epoch+1}: Train Acc={logs.get('accuracy', -1):.4f}, Val Acc={logs.get('val_accuracy', -1):.4f}")

# --- Save Best Model Callback ---
class SaveBestModel(Callback):
    def __init__(self, path='best_model.keras'):
        super().__init__()
        self.best_val = -1
        self.path = path

    def on_epoch_end(self, epoch, logs=None):
        acc = logs.get('val_accuracy', 0)
        if acc > self.best_val:
            self.best_val = acc
            self.model.save(self.path)
            print(f"✔️ New best model saved with val_acc={acc:.4f}")

callbacks = [EpochLogger(), SaveBestModel()]

# --- Train ---
model.fit(X_train, y_train,
          validation_data=(X_val, y_val),
          batch_size=64,
          epochs= 300,
          callbacks=callbacks,
          verbose=0,
          shuffle=True)

# --- Evaluate ---
val_preds = np.argmax(model.predict(X_val), axis=1)
val_true = np.argmax(y_val, axis=1)
acc = np.mean(val_preds == val_true)
print(f"Final Validation Accuracy: {acc:.4f}")

y_pred_probs = model.predict(X_val, batch_size=64)
y_pred_labels = np.argmax(y_pred_probs, axis=1) # Predicted class indices (0 or 1)
y_true_labels = np.argmax(y_val, axis=1)     # True class indices (0 or 1)

print(y_pred_labels)
print(y_true_labels)

y_pred_probs = model.predict(X_val, batch_size=64)
y_pred_labels = np.argmax(y_pred_probs, axis=1) # Predicted class indices (0 or 1)
y_true_labels = np.argmax(y_val, axis=1)     # True class indices (0 or 1)

print(y_pred_labels)
print(y_true_labels)

"""## step 1) data"""

import os, time, numpy as np, tensorflow as tf
from sklearn.model_selection import train_test_split

bandpass=(8., 20.)


bci42a_channels = [
    'Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4',
    'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',
    'CP3', 'CP1', 'CPz', 'CP2', 'CP4',
    'P1', 'Pz', 'P2', 'POz'
]

aad_custom_ch= ['C3', 'C4', 'Cz',]


# --- Config ---
set_l_1 = "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Left_10trials.set"
set_r_1= "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Right_10trials.set"
csv_left_1 = "/kaggle/input/timest/label and timestamps csv/aadhar_bicepcurl_Left_10trials.csv"
csv_right_1 = "//kaggle/input/timest/label and timestamps csv/aadhar_bicepcurl_Right_10trials.csv"

set_l_2 = "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_LeftRRight_15trials.set"
set_r_2 = set_l_2
csv_left_2 = "/kaggle/input/timest/label and timestamps csv/aadhar_bicepcurl_LeftRRight_15trials____LEFT_ONLY___.csv"
csv_right_2 = "/kaggle/input/timest/label and timestamps csv/aadhar_bicepcurl_LeftRRight_15trials____RIGHT_ONLY___.csv"


label_left = 0
label_right = 1
NUM_CLASSES = 2
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

# --- Prepare Data ---


chann_list= aad_custom_ch

#Left
X_left_1, y_left_1, sfreq = extract_epochs_from_set_and_csv(set_l_1, csv_left_1, chann_list, label=label_left, bandpass=(8., 20.))
X_left_2, y_left_2, _ = extract_epochs_from_set_and_csv(set_l_2, csv_left_2, chann_list, label=label_left, bandpass=(8., 20.))

X_right_1, y_right_1, _ = extract_epochs_from_set_and_csv(set_r_1, csv_right_1, chann_list, label=label_right,  bandpass=(8., 20.))
X_right_2, y_right_2, _ = extract_epochs_from_set_and_csv(set_r_2, csv_right_2, chann_list, label=label_right, bandpass=(8., 20.))


#X_all, y_all = combine_and_shuffle_epochs(X_left, y_left, X_right, y_right)
X_all, y_all = combine_and_shuffle_epochs ([X_left_1,X_right_1,X_left_2,X_right_2], [y_left_1,y_right_1,y_left_2,y_right_2])


y_cat = to_categorical(y_all, num_classes=NUM_CLASSES)
X_train, X_val, y_train, y_val = train_test_split(X_all, y_cat, test_size=0.3, stratify=y_all, random_state=42)

X_train.shape

"""## step 2) train"""

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, Conv2D, DepthwiseConv2D, SeparableConv2D,
    BatchNormalization, Activation, AveragePooling2D,
    Dropout, Flatten, Dense
)
from tensorflow.keras.regularizers import l2

# --- Model ---

def build_q_eegnet(input_shape, num_classes=2, dropout_rate=0.5, l2_rate=1e-4, **kwargs):
    """Placeholder 'Quantized-like' EEGNet (Lighter variant for demonstration)."""
    n_channels, n_times, _ = input_shape
    inputs = Input(shape=input_shape, name='Input')
    # Block 1 - Reduced Filters/Depth Multiplier
    F1 = 8 # Reduced from 16 in build_eegnet
    D = 1 # Reduced from 2
    kernLength = 51 # Keep same as build_eegnet
    x = Conv2D(F1, (1, kernLength), padding='same', use_bias=False, kernel_regularizer=l2(l2_rate))(inputs)
    x = BatchNormalization()(x)
    x = DepthwiseConv2D((n_channels, 1), depth_multiplier=D, use_bias=False, depthwise_regularizer=l2(l2_rate))(x)
    x = BatchNormalization()(x)
    x = Activation('elu')(x)
    x = AveragePooling2D((1, 4))(x)
    x = Dropout(dropout_rate)(x)
    # Block 2 - Reduced Filters
    F2 = 16 # Reduced from 32
    kernLength2 = 15 # Keep same as build_eegnet
    x = SeparableConv2D(F2, (1, kernLength2), padding='same', use_bias=False, depthwise_regularizer=l2(l2_rate), pointwise_regularizer=l2(l2_rate))(x)
    x = BatchNormalization()(x)
    x = Activation('elu')(x)
    x = AveragePooling2D((1, 8))(x)
    x = Dropout(dropout_rate)(x)
    # Classification Head - Reduced Dense Layer
    x = Flatten()(x)
    x = Dense(32, activation='elu', kernel_regularizer=l2(l2_rate))(x) # Reduced from 64
    x = Dropout(dropout_rate)(x)
    outputs = Dense(num_classes, activation='softmax')(x)
    return Model(inputs, outputs, name='build_q_eegnet')


input_shape = X_train.shape[1:]
model = build_q_eegnet(input_shape=input_shape, num_classes=NUM_CLASSES, dropout_rate=0.25, l2_rate=0.0001)
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# --- Logging Callback ---
class EpochLogger(Callback):
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        print(f"Epoch {epoch+1}: Train Acc={logs.get('accuracy', -1):.4f}, Val Acc={logs.get('val_accuracy', -1):.4f}")

# --- Save Best Model Callback ---
class SaveBestModel(Callback):
    def __init__(self, path='best_model.keras'):
        super().__init__()
        self.best_val = -1
        self.path = path

    def on_epoch_end(self, epoch, logs=None):
        acc = logs.get('val_accuracy', 0)
        if acc > self.best_val:
            self.best_val = acc
            self.model.save(self.path)
            print(f"✔️ New best model saved with val_acc={acc:.4f}")

callbacks = [EpochLogger(), SaveBestModel()]

# --- Train ---
model.fit(X_train, y_train,
          validation_data=(X_val, y_val),
          batch_size=64,
          epochs= 300,
          callbacks=callbacks,
          verbose=0,
          shuffle=True)

# --- Evaluate ---
val_preds = np.argmax(model.predict(X_val), axis=1)
val_true = np.argmax(y_val, axis=1)
acc = np.mean(val_preds == val_true)
print(f"Final Validation Accuracy: {acc:.4f}")

y_train.shape

"""## -----------PART 2 A- full train"""

import os, time, numpy as np, tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical


# --- Config ---
set_l_1 = "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Left_10trials.set"
set_r_1= "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Right_10trials.set"
csv_left_1 = "/kaggle/input/timest/label and timestamps csv/aadhar_bicepcurl_Left_10trials.csv"
csv_right_1 = "//kaggle/input/timest/label and timestamps csv/aadhar_bicepcurl_Right_10trials.csv"

set_l_2 = "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_LeftRRight_15trials.set"
set_r_2 = set_l_2
csv_left_2 = "/kaggle/input/timest/label and timestamps csv/aadhar_bicepcurl_LeftRRight_15trials____LEFT_ONLY___.csv"
csv_right_2 = "/kaggle/input/timest/label and timestamps csv/aadhar_bicepcurl_LeftRRight_15trials____RIGHT_ONLY___.csv"


label_left = 0
label_right = 1
NUM_CLASSES = 2
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

# --- Prepare Data ---

#Left
X_left_1, y_left_1, sfreq = extract_epochs_from_set_and_csv(set_l_1, csv_left_1, label=label_left)
X_left_2, y_left_2, _ = extract_epochs_from_set_and_csv(set_l_2, csv_left_2, label=label_left)

X_right_1, y_right_1, _ = extract_epochs_from_set_and_csv(set_r_1, csv_right_1, label=label_right)
X_right_2, y_right_2, _ = extract_epochs_from_set_and_csv(set_r_2, csv_right_2, label=label_right)


#X_all, y_all = combine_and_shuffle_epochs(X_left, y_left, X_right, y_right)
X_all, y_all = combine_and_shuffle_epochs ([X_left_1,X_right_1,X_left_2,X_right_2], [y_left_1,y_right_1,y_left_2,y_right_2])






'''
y_cat = to_categorical(y_all, num_classes=NUM_CLASSES)
X_train, X_val, y_train, y_val = train_test_split(X_all, y_cat, test_size=0.3, stratify=y_all, random_state=42)
'''

"""## data compatibility - bci & aad data

channel select
"""

'''# Get indices of BCI channels in your custom dataset
all_channels = [
    'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',
    'F7', 'F8', 'T7', 'T8', 'P7', 'P8', 'Fz', 'Cz', 'Pz', 'IO',
    'FC1', 'FC2', 'CP1', 'CP2', 'FC5', 'FC6', 'CP5', 'CP6',
    'FT9', 'FT10', 'TP9', 'TP10'
]

bci_channels = [
    'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',
    'F7', 'F8', 'T7', 'T8', 'P7', 'P8', 'Fz', 'Cz', 'Pz',
    'FC1', 'FC2', 'CP1', 'CP2'
]

#selected_indices = [all_channels.index(ch) for ch in bci42a_channels if ch in all_channels]

#print("Selected channel indices:", selected_indices)
#print("Matched channel names:", [all_channels[i] for i in selected_indices])

#Matched channel names: ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',
                        #'F7', 'F8', 'T7', 'T8', 'P7', 'P8', 'Fz', 'Cz', 'Pz',
                       #'FC1', 'FC2', 'CP1', 'CP2']
selected_indices= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23]

selected_indices'''

#selected_indices

selected_indices= [16, 24, 20, 4, 21, 25, 17, 5, 26, 22, 23, 27, 6, 18, 7, 8, 9, 20, 21, 4, 5, 7]
selected_names: ['Fz', 'FC5', 'FC1', 'C3', 'FC2', 'FC6', 'Cz', 'C4',
                         'CP5', 'CP1', 'CP2', 'CP6', 'P3', 'Pz', 'P4',
                         'O1', 'O2', 'FC1', 'FC2', 'C3', 'C4', 'P4']

# After combining epochs from both limbs

# Apply post-processing
X_clean, kept_idx, new_sfreq = preprocess_epochs(
    X_all,
    sfreq=500,
    reject_thresh_uv=150,
    downsample_to=250,           # Optional: downsample to 128 Hz
    selected_channels= selected_indices   ) #list(range(0, 16))  # Optional: keep first 16 EEG channels


# Sync labels
y_clean = y_all[kept_idx]

y_cat = to_categorical(y_clean, num_classes=NUM_CLASSES)
X_train, X_val, y_train, y_val = train_test_split(X_clean, y_cat, test_size=0.3, stratify=y_clean, random_state=42)
X_train.shape

# Ensure shape is (samples, channels, time, 1)
print(X_train.shape)
if X_train.ndim == 3:
    X_train = X_train[..., np.newaxis]
    X_val = X_val[..., np.newaxis]
print(X_train.shape)

# Pad 1 sample at the end
X_train = np.pad(X_train, ((0, 0), (0, 0), (0, 1), (0, 0)), mode='constant')
X_val = np.pad(X_val, ((0, 0), (0, 0), (0, 1), (0, 0)), mode='constant')
print(X_train.shape)

X_train.shape[2]

target_time_len = 751
current_time_len = X_train.shape[2]
pad_len = target_time_len - current_time_len

if pad_len > 0:
    X_train = np.pad(X_train, ((0, 0), (0, 0), (0, pad_len), (0, 0)), mode='constant')
    X_val = np.pad(X_val, ((0, 0), (0, 0), (0, pad_len), (0, 0)), mode='constant')
elif pad_len < 0:
    # Crop if too long
    X_train = X_train[:, :, :target_time_len, :]
    X_val = X_val[:, :, :target_time_len, :]

X_train.shape



'''#-----> confirm bci 42a samp_freq
raw = mne.io.read_raw_gdf("/kaggle/input/bci-4-2a/A01T.gdf", preload=False, verbose='warning')
sfreq = raw.info['sfreq']
sfreq'''

raw.info['ch_names']

"""### Train"""



from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, Conv2D, DepthwiseConv2D, SeparableConv2D,
    BatchNormalization, Activation, AveragePooling2D,
    Dropout, Flatten, Dense
)
from tensorflow.keras.regularizers import l2

# --- Model ---
'''
def build_q_eegnet(input_shape, num_classes=2, dropout_rate=0.5, l2_rate=1e-4, **kwargs):
    """Placeholder 'Quantized-like' EEGNet (Lighter variant for demonstration)."""
    n_channels, n_times, _ = input_shape
    inputs = Input(shape=input_shape, name='Input')
    # Block 1 - Reduced Filters/Depth Multiplier
    F1 = 8 # Reduced from 16 in build_eegnet
    D = 1 # Reduced from 2
    kernLength = 51 # Keep same as build_eegnet
    x = Conv2D(F1, (1, kernLength), padding='same', use_bias=False, kernel_regularizer=l2(l2_rate))(inputs)
    x = BatchNormalization()(x)
    x = DepthwiseConv2D((n_channels, 1), depth_multiplier=D, use_bias=False, depthwise_regularizer=l2(l2_rate))(x)
    x = BatchNormalization()(x)
    x = Activation('elu')(x)
    x = AveragePooling2D((1, 4))(x)
    x = Dropout(dropout_rate)(x)
    # Block 2 - Reduced Filters
    F2 = 16 # Reduced from 32
    kernLength2 = 15 # Keep same as build_eegnet
    x = SeparableConv2D(F2, (1, kernLength2), padding='same', use_bias=False, depthwise_regularizer=l2(l2_rate), pointwise_regularizer=l2(l2_rate))(x)
    x = BatchNormalization()(x)
    x = Activation('elu')(x)
    x = AveragePooling2D((1, 8))(x)
    x = Dropout(dropout_rate)(x)
    # Classification Head - Reduced Dense Layer
    x = Flatten()(x)
    x = Dense(32, activation='elu', kernel_regularizer=l2(l2_rate))(x) # Reduced from 64
    x = Dropout(dropout_rate)(x)
    outputs = Dense(num_classes, activation='softmax')(x)
    return Model(inputs, outputs, name='build_q_eegnet')
'''


input_shape = X_train.shape[1:]
#model = build_q_eegnet(input_shape=input_shape, num_classes=NUM_CLASSES, dropout_rate=0.25, l2_rate=0.0001)
from tensorflow.keras.models import load_model
model_ = load_model("/kaggle/input/bci_42q/keras/default/1/best_model_BCI_traied_qeegnet.keras")


optimizer = Adam(learning_rate=0.001)
model_.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# --- Logging Callback ---
class EpochLogger(Callback):
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        print(f"Epoch {epoch+1}: Train Acc={logs.get('accuracy', -1):.4f}, Val Acc={logs.get('val_accuracy', -1):.4f}")

# --- Save Best Model Callback ---
class SaveBestModel(Callback):
    def __init__(self, path='best_model.keras'):
        super().__init__()
        self.best_val = -1
        self.path = path

    def on_epoch_end(self, epoch, logs=None):
        acc = logs.get('val_accuracy', 0)
        if acc > self.best_val:
            self.best_val = acc
            self.model.save(self.path)
            print(f"✔️ New best model saved with val_acc={acc:.4f}")

callbacks = [EpochLogger(), SaveBestModel()]

# --- Train ---
model_.fit(X_train, y_train,
          validation_data=(X_val, y_val),
          batch_size=64,
          epochs= 300,
          callbacks=callbacks,
          verbose=0,
          shuffle=True)


#----



# --- Evaluate ---
val_preds = np.argmax(model_.predict(X_val), axis=1)
val_true = np.argmax(y_val, axis=1)
acc = np.mean(val_preds == val_true)
print(f"Final Validation Accuracy: {acc:.4f}")

"""(115, 22, 751, 1) - trials, chann,"""

X_tr_c.shape

"""-- New best model saved with val_acc=0.7931

"""





#training_time = timing_callback.get_total_time() if 'timing_callback' in locals() else -1.0
epochs_ran = len(history.history['loss']) if history and 'loss' in history.history else 0
        #logging.error(f"An error occurred during training or evaluation: {fit_eval_error}", exc_info=True)
val_acc, val_loss = -1.0, -1.0; precision, recall, f1_score = -1.0, -1.0, -1.0
        #current_error = f"FitEvalError: {fit_eval_error}"

    # --- Plotting ---
if history and epochs_ran > 0: # Only plot if training actually happened
        logging.info("Generating training history plots...")
        #epoch_times_list = timing_callback.get_epoch_times()[:epochs_ran]
        # Pad with 0 for the start time at epoch 0
        #cumulative_time = np.cumsum([0] + epoch_times_list)
        epoch_axis = range(epochs_ran) # Epochs are 0 to epochs_ran-1

        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
#        fig.suptitle(f'Run {i+1}: {model_name}\n{config_str}', fontsize=9) # Slightly smaller font
        fig.suptitle(f'Run {0+1}: {model_name}\n', fontsize=9) # Slightly smaller font

        # Accuracy Plot
if 'accuracy' in history.history and 'val_accuracy' in history.history:
            axes[0].plot(epoch_axis, history.history['accuracy'], label='Train Acc')
            axes[0].plot(epoch_axis, history.history['val_accuracy'], label='Val Acc')
            axes[0].set_title('Accuracy vs. Epoch'); axes[0].set_xlabel('Epoch'); axes[0].legend(); axes[0].grid(True)
else: axes[0].set_title('Accuracy Plot Unavailable'); axes[0].text(0.5, 0.5, 'No Data', ha='center', va='center')

        # Loss Plot
if 'loss' in history.history and 'val_loss' in history.history:
            axes[1].plot(epoch_axis, history.history['loss'], label='Train Loss')
            axes[1].plot(epoch_axis, history.history['val_loss'], label='Val Loss')
            axes[1].set_title('Loss vs. Epoch'); axes[1].set_xlabel('Epoch'); axes[1].legend(); axes[1].grid(True)
else: axes[1].set_title('Loss Plot Unavailable'); axes[1].text(0.5, 0.5, 'No Data', ha='center', va='center')

        # Cumulative Time Plot
        # Need epochs_ran + 1 points for cumulative time plot (includes time=0 at epoch 0)
#---

plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap

plt.show()

plt.close(fig)







"""### try 1"""

import mne
import pandas as pd

def load_custom_set_and_events(set_file, csv_file, event_id_map, tmin=0.0, tmax=3.0):
    raw = mne.io.read_raw_eeglab(set_file, preload=True)
    sfreq = raw.info['sfreq']

    # Bandpass filter
    raw.filter(5., 35., fir_design='firwin')

    # Load events from CSV
    events_df = pd.read_csv(csv_file)  # Should have 'onset' and 'label'
    events = np.array([[int(row['onset']), 0, int(event_id_map[row['label']])] for _, row in events_df.iterrows()])

    epochs = mne.Epochs(raw, events, event_id=event_id_map, tmin=tmin, tmax=tmax, baseline=None, preload=True)
    X = epochs.get_data()[..., np.newaxis]
    y = np.array([event_id_map[label] for label in epochs.events[:, -1]])
    y_cat = tf.keras.utils.to_categorical(y, num_classes=len(event_id_map))

    return train_test_split(X, y_cat, test_size=0.2, random_state=42, stratify=y)

set_file = "/kaggle/input/aad-eeg-data/SET files extracted from vhdr files/aadhar_bicepcurl_Left_10trials.set"
csv_file= "/kaggle/input/timestamps/label and timestamps csv/aadhar_bicepcurl_Left_10trials.csv"
d= load_custom_set_and_events(set_file, csv_file, event_id_map, tmin=0.0, tmax=3.0)
len(d)